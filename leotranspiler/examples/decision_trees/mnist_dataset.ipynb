{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of a decision tree Leo transpilation for the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a decision tree to classify images on datasets like the MNIST dataset may seem a bit of an unusual approach - but we want to show it is possible, even in a zero-knowledge environment! Inspired by [this project](https://www.kaggle.com/code/carlolepelaars/97-on-mnist-with-a-single-decision-tree-t-sne), the trick is to transform the data before passing it to the decision tree. We use the techniques of ??? and t-SNE to reduce the dataset dimensionality and make it separable by a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_extract_dataset(url, save_path, folder_path):\n",
    "    \"\"\"Download and extract dataset if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f\"Downloading {os.path.basename(save_path)}...\")\n",
    "        response = requests.get(url)\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        decompressed_file_name = os.path.splitext(os.path.basename(save_path))[0]\n",
    "        decompressed_file_path = os.path.join(folder_path, decompressed_file_name)\n",
    "\n",
    "        with gzip.open(save_path, \"rb\") as f_in:\n",
    "            with open(decompressed_file_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        print(f\"{decompressed_file_name} downloaded and extracted.\")\n",
    "    else:\n",
    "        print(f\"{os.path.basename(save_path)} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz already exists.\n",
      "train-labels-idx1-ubyte.gz already exists.\n",
      "t10k-images-idx3-ubyte.gz already exists.\n",
      "t10k-labels-idx1-ubyte.gz already exists.\n"
     ]
    }
   ],
   "source": [
    "# URLs and filenames\n",
    "file_info = [\n",
    "    (\n",
    "        \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\",\n",
    "        \"train-images-idx3-ubyte.gz\",\n",
    "    ),\n",
    "    (\n",
    "        \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\",\n",
    "        \"train-labels-idx1-ubyte.gz\",\n",
    "    ),\n",
    "    (\n",
    "        \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "        \"t10k-images-idx3-ubyte.gz\",\n",
    "    ),\n",
    "    (\n",
    "        \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\",\n",
    "        \"t10k-labels-idx1-ubyte.gz\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "folder_name = \"tmp/mnist\"\n",
    "folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "\n",
    "os.makedirs(folder_path, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Download and extract each file\n",
    "for url, file_name in file_info:\n",
    "    path_to_save = os.path.join(folder_path, file_name)\n",
    "    download_and_extract_dataset(url, path_to_save, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_images: (60000, 28, 28)\n",
      "Shape of train_labels: (60000,)\n",
      "Shape of test_images: (10000, 28, 28)\n",
      "Shape of test_labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_idx3_ubyte_image_file(filename):\n",
    "    \"\"\"Read IDX3-ubyte formatted image data.\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic_num = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "        num_images = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "        num_rows = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "        num_cols = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "\n",
    "        if magic_num != 2051:\n",
    "            raise ValueError(f\"Invalid magic number: {magic_num}\")\n",
    "\n",
    "        images = np.zeros((num_images, num_rows, num_cols), dtype=np.uint8)\n",
    "\n",
    "        for i in range(num_images):\n",
    "            for r in range(num_rows):\n",
    "                for c in range(num_cols):\n",
    "                    pixel = int.from_bytes(f.read(1), byteorder=\"big\")\n",
    "                    images[i, r, c] = pixel\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_idx1_ubyte_label_file(filename):\n",
    "    \"\"\"Read IDX1-ubyte formatted label data.\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic_num = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "        num_labels = int.from_bytes(f.read(4), byteorder=\"big\")\n",
    "\n",
    "        if magic_num != 2049:\n",
    "            raise ValueError(f\"Invalid magic number: {magic_num}\")\n",
    "\n",
    "        labels = np.zeros(num_labels, dtype=np.uint8)\n",
    "\n",
    "        for i in range(num_labels):\n",
    "            labels[i] = int.from_bytes(f.read(1), byteorder=\"big\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Example usage\n",
    "folder_path = os.path.join(\n",
    "    os.getcwd(), folder_name\n",
    ")  # Adjust this path to where you stored the files\n",
    "\n",
    "train_images = read_idx3_ubyte_image_file(\n",
    "    os.path.join(folder_path, \"train-images-idx3-ubyte\")\n",
    ")\n",
    "train_labels = read_idx1_ubyte_label_file(\n",
    "    os.path.join(folder_path, \"train-labels-idx1-ubyte\")\n",
    ")\n",
    "test_images = read_idx3_ubyte_image_file(\n",
    "    os.path.join(folder_path, \"t10k-images-idx3-ubyte\")\n",
    ")\n",
    "test_labels = read_idx1_ubyte_label_file(\n",
    "    os.path.join(folder_path, \"t10k-labels-idx1-ubyte\")\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Shape of train_images: {train_images.shape}\"\n",
    ")  # Should output \"Shape of train_images: (60000, 28, 28)\"\n",
    "print(\n",
    "    f\"Shape of train_labels: {train_labels.shape}\"\n",
    ")  # Should output \"Shape of train_labels: (60000,)\"\n",
    "print(\n",
    "    f\"Shape of test_images: {test_images.shape}\"\n",
    ")  # Should output \"Shape of test_images: (10000, 28, 28)\"\n",
    "print(\n",
    "    f\"Shape of test_labels: {test_labels.shape}\"\n",
    ")  # Should output \"Shape of test_labels: (10000,)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the datasets from 3D to 2D\n",
    "train_images_2d = train_images.reshape(\n",
    "    train_images.shape[0], -1\n",
    ")  # -1 infers the size from the remaining dimensions\n",
    "test_images_2d = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "# Create the classifier and fit it to the reshaped training data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(train_images_2d, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for our baseline (using all pixel features): 89.95%\n",
      "Validation accuracy for our baseline (using all pixel features): 86.57%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred) * 100  # Multiply by 100 to get percentage\n",
    "\n",
    "\n",
    "# Evaluate the baseline model\n",
    "train_preds_baseline = clf.predict(train_images_2d)\n",
    "val_preds_baseline = clf.predict(test_images_2d)\n",
    "acc_baseline_train = acc(train_preds_baseline, train_labels)\n",
    "acc_baseline_val = acc(val_preds_baseline, test_labels)\n",
    "print(\n",
    "    f\"Training accuracy for our baseline (using all pixel features): {acc_baseline_train:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation accuracy for our baseline (using all pixel features): {acc_baseline_val:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vv/tpx839bx0fv237mr6s68w1nh0000gn/T/ipykernel_43604/1350906072.py\", line 6, in <module>\n",
      "    plt.show()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py\", line 446, in show\n",
      "    return _get_backend_mod().show(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/matplotlib_inline/backend_inline.py\", line 90, in show\n",
      "    display(\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/display_functions.py\", line 298, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/formatters.py\", line 179, in format\n",
      "    data = formatter(obj)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/formatters.py\", line 340, in __call__\n",
      "    return printer(obj)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py\", line 152, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/matplotlib/backend_bases.py\", line 2346, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/matplotlib/figure.py\", line 1776, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/matplotlib/axes/_base.py\", line -1, in get_tightbbox\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/kp/Library/Python/3.11/lib/python/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plot_tree(clf, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from leotranspiler import LeoTranspiler\n",
    "\n",
    "# Set the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Transpile the deceision tree into Leo code\n",
    "lt = LeoTranspiler(model=clf, validation_data=train_images_2d[0:50])\n",
    "leo_project_path = os.path.join(os.getcwd(), \"tmp/mnist\")\n",
    "leo_project_name = \"tree_credit\"\n",
    "lt.to_leo(path=leo_project_path, project_name=leo_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prove and compare the Leo prediction with the Python prediction and the label\n",
    "zkp = lt.execute(input_sample=train_images_2d[0])\n",
    "python_prediction = clf.predict([train_images_2d[0]])\n",
    "\n",
    "print(f\"Circuit constraints: {zkp.circuit_constraints}\")\n",
    "print(f\"Active input count: {zkp.active_input_count}\")\n",
    "print(f\"Leo prediction in fixed-point notation: {zkp.output[0]}\")\n",
    "print(f\"Leo prediction in decimal notation: {zkp.output_decimal[0]}\")\n",
    "print(f\"Python prediction: {python_prediction[0]}\")\n",
    "print(f\"Label: {test_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Fit the model to the training data\n",
    "tsvd = TruncatedSVD(n_components=50)\n",
    "tsvd.fit(train_images_2d)\n",
    "\n",
    "# Transform both training and test datasets using the fitted model\n",
    "train_tsvd = tsvd.transform(train_images_2d)\n",
    "test_tsvd = tsvd.transform(test_images_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with t-svd features\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(train_tsvd, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tsvd model\n",
    "train_preds_tsvd = clf.predict(train_tsvd)\n",
    "val_preds_tsvd = clf.predict(test_tsvd)\n",
    "acc_tsvd_train = acc(train_preds_tsvd, train_labels)\n",
    "acc_tsvd_val = acc(val_preds_tsvd, test_labels)\n",
    "print(\n",
    "    f\"Training accuracy for our tsvd (using all pixel features): {acc_tsvd_train:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation accuracy for our tsvd (using all pixel features): {acc_tsvd_val:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jsilter/parametric_tsne\n",
    "from parametric_tSNE import Parametric_tSNE\n",
    "\n",
    "train_data = train_tsvd\n",
    "\n",
    "high_dims = train_data.shape[1]\n",
    "num_outputs = 2\n",
    "perplexity = 30\n",
    "ptSNE = Parametric_tSNE(high_dims, num_outputs, perplexity)\n",
    "ptSNE.fit(train_data)\n",
    "output_res = ptSNE.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = ptSNE.transform(test_tsvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output_res))\n",
    "print(output_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform output_res to a pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(output_res, columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Visualize the results for t-SNE on MNIST\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.title(\n",
    "    f\"Visualization of t-SNE results on the MNIST Dataset\\n\\\n",
    "Amount of datapoints: {len(df)}\",\n",
    "    fontsize=24,\n",
    "    weight=\"bold\",\n",
    ")\n",
    "sns.scatterplot(data=df, palette=\"Set1\", legend=\"full\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Component 1\", fontsize=16)\n",
    "plt.ylabel(\"Component 2\", fontsize=16)\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(output_res, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_preds_tsvd = clf.predict(output_res)\n",
    "val_preds_tsvd = clf.predict(test_res)\n",
    "acc_tsvd_train = acc(train_preds_tsvd, train_labels)\n",
    "acc_tsvd_val = acc(val_preds_tsvd, test_labels)\n",
    "print(\n",
    "    f\"Training accuracy for our tsvd (using all pixel features): {acc_tsvd_train:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation accuracy for our tsvd (using all pixel features): {acc_tsvd_val:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)  # Number of components to keep\n",
    "pca.fit(train_images_2d)\n",
    "transformed_train = pca.transform(train_images_2d)\n",
    "transformed_test = pca.transform(test_images_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=6, random_state=0)\n",
    "clf.fit(transformed_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_preds_tsvd = clf.predict(transformed_train)\n",
    "val_preds_tsvd = clf.predict(transformed_test)\n",
    "acc_tsvd_train = acc(train_preds_tsvd, train_labels)\n",
    "acc_tsvd_val = acc(val_preds_tsvd, test_labels)\n",
    "print(\n",
    "    f\"Training accuracy for our tsvd (using all pixel features): {acc_tsvd_train:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation accuracy for our tsvd (using all pixel features): {acc_tsvd_val:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "\n",
    "def average_intensity(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "\n",
    "def num_white_regions(image, threshold=128):\n",
    "    # Threshold the image to convert it to binary\n",
    "    bin_image = (image > threshold).astype(int)\n",
    "    # Use scipy's label function to count connected regions\n",
    "    labeled_array, num_features = label(bin_image)\n",
    "    return num_features\n",
    "\n",
    "\n",
    "# Calculate new features for training set\n",
    "avg_intensity_train = np.array([average_intensity(img) for img in train_images_2d])\n",
    "white_regions_train = np.array([num_white_regions(img) for img in train_images_2d])\n",
    "\n",
    "# Calculate new features for test set\n",
    "avg_intensity_test = np.array([average_intensity(img) for img in test_images_2d])\n",
    "white_regions_test = np.array([num_white_regions(img) for img in test_images_2d])\n",
    "\n",
    "# Combine old and new features for training set\n",
    "X_new_train = np.c_[train_images_2d, avg_intensity_train, white_regions_train]\n",
    "\n",
    "# Combine old and new features for test set\n",
    "X_new_test = np.c_[test_images_2d, avg_intensity_test, white_regions_test]\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10)\n",
    "tree_clf.fit(X_new_train, train_labels)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Train score:\", tree_clf.score(X_new_train, train_labels))\n",
    "print(\"Test score:\", tree_clf.score(X_new_test, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LeoTranspiler(model=tree_clf, validation_data=train_images_2d[0:50])\n",
    "leo_project_path = os.path.join(os.getcwd(), \"tmp/mnist\")\n",
    "leo_project_name = \"tree_credit\"\n",
    "lt.to_leo(path=leo_project_path, project_name=leo_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_2d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prove and compare the Leo prediction with the Python prediction and the label\n",
    "zkp = lt.execute(input_sample=X_new_train[0])\n",
    "python_prediction = tree_clf.predict([X_new_train[0]])\n",
    "\n",
    "print(f\"Circuit constraints: {zkp.circuit_constraints}\")\n",
    "print(f\"Active input count: {zkp.active_input_count}\")\n",
    "print(f\"Leo prediction in fixed-point notation: {zkp.output[0]}\")\n",
    "print(f\"Leo prediction in decimal notation: {zkp.output_decimal[0]}\")\n",
    "print(f\"Python prediction: {python_prediction[0]}\")\n",
    "print(f\"Label: {test_labels[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
